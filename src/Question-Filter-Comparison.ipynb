{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook compares two approaches for extracting questions from text: (1) Using basic rule-based method with regex (2) Constituent parse trees from CoreNLP\n",
    "\n",
    "- Manually annotate 300 samples from 4 subreddits (75 from each); and compare the outputs of the two approaches with the manually identified questions.\n",
    "\n",
    "#### Useful links:\n",
    "- CoreNLP Annotators: https://stanfordnlp.github.io/CoreNLP/annotators.html\n",
    "- Penn Treebank tags: https://gist.github.com/nlothian/9240750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ndg/users/sbagga1/.local/lib/python2.7/site-packages/requests/__init__.py:83: RequestsDependencyWarning: Old version of cryptography ([1, 2, 3]) may cause slowdown.\n",
      "  warnings.warn(warning, RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Regex approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_questions_regex(comment):\n",
    "    \"\"\"\n",
    "    Extracts questions from a given comment using simple regular expression and sentence tokenization.\n",
    "    Note: gets rid of non-ASCII characters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    comment: str\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of strings where each string corresponds to a question.\n",
    "    \"\"\"\n",
    "    questions = []\n",
    "    \n",
    "    clean_comment = re.sub(r'[!.,?]*\\?[!.,?]*', '? ', comment) # substitute multiple !??.. with a single \"?\"\n",
    "    clean_comment = re.sub(r'\\.+\\.', '. ', clean_comment) # substitute multiple .... with a single \".\"\n",
    "    \n",
    "    sentences = sent_tokenize(clean_comment)\n",
    "    for sent in sentences:\n",
    "        sent = sent.strip()\n",
    "        if sent.endswith('?'): # gets rid of quoting questions: Sometimes she's hot, then other times you're like, \"did you just get out of a car accident?\"\n",
    "            questions.append(sent)\n",
    "            \n",
    "    return questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CoreNLP parsing approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('http://localhost:9000') # connect to server\n",
    "\n",
    "# 'parse' provides full syntactic analysis, using both the constituent and the dependency representations.\n",
    "def annotate_comment(comment):\n",
    "    res = nlp.annotate(comment,\n",
    "                       properties={\n",
    "                       'annotators': 'parse',\n",
    "                       'outputFormat': 'json',\n",
    "                       'timeout': 1000,\n",
    "                    })\n",
    "    \n",
    "    return res\n",
    "\n",
    "def extract_questions_CoreNLP(comment):\n",
    "    questions = []\n",
    "\n",
    "    # CoreNLP server:\n",
    "    res = annotate_comment(comment)\n",
    "\n",
    "    # Question if contains SBARQ and SQ\n",
    "    for output in res['sentences']:\n",
    "        parse_tree = output['parse']\n",
    "        parse_output = parse_tree.split('(')\n",
    "\n",
    "        if parse_output[0] == '' and parse_output[1].startswith('ROOT'):\n",
    "            if parse_output[2].startswith('SBARQ') or parse_output[2].startswith('SQ'):\n",
    "                questions.append(\" \".join([t[\"word\"] for t in output[\"tokens\"]]))\n",
    "\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comment(text):\n",
    "    \"\"\"\n",
    "    Cleans the given text. Removes URL links. Removes non-ASCII characters.\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"http\\S+\", \"\", text) # remove URL links\n",
    "    return ''.join([i if ord(i) < 128 else '' for i in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic ? approach:  ['Can you do this for me?', 'Is your pride too big?', 'Involved much?', 'hey how are you?']\n",
      "\n",
      "CoreNLP Parsing approach:  [u'Can you do this for me !!??', u\"Ca n't you do anything right .\", u'Is your pride too big ?']\n"
     ]
    }
   ],
   "source": [
    "comment = \"Hey you. Can you do this for me!!?? Can't you do anything right..you shit. Is your pride too big? Involved much? \\\n",
    "           Not true, at all. https://www.youtube.com/watch?v=C6QEqoYgQxw   hey how are you?\"\n",
    "\n",
    "print \"\\nBasic ? approach: \", extract_questions_regex(clean_comment(comment))\n",
    "print \"\\nCoreNLP Parsing approach: \", extract_questions_CoreNLP(clean_comment(comment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract questions from 4 subreddits:\n",
    "- Using both approaches.\n",
    "- 75 samples from each subreddit for a total of 300 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBREDDITS = ['cringe', 'nfl', 'PoliticalDiscussion', 'The_Donald'] # Test subreddits for comparing the two approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle loaded:  cringe\n",
      "Pickle loaded:  nfl\n",
      "Pickle loaded:  PoliticalDiscussion\n",
      "Pickle loaded:  The_Donald\n"
     ]
    }
   ],
   "source": [
    "inp_dict = {'Questions_Basic':[], 'Questions_CoreNLP': [], 'Comment_Text':[], 'Reply_Text':[], 'Comment_ID':[], 'Reply_ID':[], \n",
    "            'Subreddit':[]}\n",
    "\n",
    "for subred in SUBREDDITS:    \n",
    "    with open('../pickles/subreddit_interactions_withIDs/'+subred+'-interactions.pickle', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print \"Pickle loaded: \", subred\n",
    "    \n",
    "    counter = 0\n",
    "    for user_tup, conversation in data.items():\n",
    "        for interaction in conversation: # interaction is a (comment,reply) tuple so it's length is always 2\n",
    "            comment_id = interaction[0][0]\n",
    "            comment_text = interaction[0][1]\n",
    "\n",
    "            reply_id = interaction[1][0]\n",
    "            reply_text = interaction[1][1]\n",
    "\n",
    "            reply_text = clean_comment(reply_text)\n",
    "            \n",
    "            try:\n",
    "                questions_basic = extract_questions_regex(reply_text)\n",
    "                questions_coreNLP = extract_questions_CoreNLP(reply_text)\n",
    "            except:\n",
    "                print \"This didn't work: \", reply_text\n",
    "                continue\n",
    "\n",
    "            inp_dict['Questions_Basic'].append(questions_basic)\n",
    "            inp_dict['Questions_CoreNLP'].append(questions_coreNLP)\n",
    "            inp_dict['Comment_Text'].append(comment_text)\n",
    "            inp_dict['Reply_Text'].append(reply_text)\n",
    "            inp_dict['Comment_ID'].append(comment_id)\n",
    "            inp_dict['Reply_ID'].append(reply_id)\n",
    "            inp_dict['Subreddit'].append(subred)\n",
    "            \n",
    "            counter += 1\n",
    "            \n",
    "        if counter >= 75:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(302, 7)\n"
     ]
    }
   ],
   "source": [
    "# Turn into a dataframe:\n",
    "df = pd.DataFrame.from_dict(inp_dict, orient='columns')\n",
    "\n",
    "cols = [u'Reply_Text', u'Questions_Basic', u'Questions_CoreNLP', u'Comment_Text', u'Comment_ID', u'Reply_ID', u'Subreddit']\n",
    "df = df[cols]\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reply_Text</th>\n",
       "      <th>Questions_Basic</th>\n",
       "      <th>Questions_CoreNLP</th>\n",
       "      <th>Comment_Text</th>\n",
       "      <th>Comment_ID</th>\n",
       "      <th>Reply_ID</th>\n",
       "      <th>Subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You're thinking of Mel Gibson.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>His performance in Space Balls was top notch.</td>\n",
       "      <td>czb7buz</td>\n",
       "      <td>czba13l</td>\n",
       "      <td>cringe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>that deescalated quickly</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>That went from 100 to 0 real fucking quick.</td>\n",
       "      <td>czc6hot</td>\n",
       "      <td>czci4z7</td>\n",
       "      <td>cringe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"That was our one year cake\"\\n\\n\\nThat's ok de...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Start of a good marrage.</td>\n",
       "      <td>44rqt6</td>\n",
       "      <td>cztpx3n</td>\n",
       "      <td>cringe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Couldn't do it</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Could n't do it]</td>\n",
       "      <td>3 Guys breaking up with girls they are not dating</td>\n",
       "      <td>4fy9zm</td>\n",
       "      <td>d2d1y4a</td>\n",
       "      <td>cringe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All I'm saying is that Trump was clearly talki...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>&amp;gt;The absolute vast majority of illegal immi...</td>\n",
       "      <td>czcwtxo</td>\n",
       "      <td>czcx098</td>\n",
       "      <td>cringe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Reply_Text Questions_Basic  \\\n",
       "0                     You're thinking of Mel Gibson.              []   \n",
       "1                           that deescalated quickly              []   \n",
       "2  \"That was our one year cake\"\\n\\n\\nThat's ok de...              []   \n",
       "3                                     Couldn't do it              []   \n",
       "4  All I'm saying is that Trump was clearly talki...              []   \n",
       "\n",
       "   Questions_CoreNLP                                       Comment_Text  \\\n",
       "0                 []      His performance in Space Balls was top notch.   \n",
       "1                 []        That went from 100 to 0 real fucking quick.   \n",
       "2                 []                           Start of a good marrage.   \n",
       "3  [Could n't do it]  3 Guys breaking up with girls they are not dating   \n",
       "4                 []  &gt;The absolute vast majority of illegal immi...   \n",
       "\n",
       "  Comment_ID Reply_ID Subreddit  \n",
       "0    czb7buz  czba13l    cringe  \n",
       "1    czc6hot  czci4z7    cringe  \n",
       "2     44rqt6  cztpx3n    cringe  \n",
       "3     4fy9zm  d2d1y4a    cringe  \n",
       "4    czcwtxo  czcx098    cringe  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### df.to_csv('../coreNLP_vs_Regex_302.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats:\n",
    "- Manual Analysis: \n",
    "    - Total of 302 comments. They contain a total of 697 sentences.\n",
    "    - 241 comments have no questions in them.\n",
    "    - 61 comments contain a total of 81 questions.\n",
    "    - Out of these 81 questions, 7 did not have a question mark:\n",
    "        1. \"holy shit don't you have anything better to do.\" [22]\n",
    "        2. \"Jesus fucking Christ how is this not top of the sub.\" [35]\n",
    "        3. \"wat\" [42]\n",
    "        4. \"Was wondering why this was up voted\" [62] (Indirect Question)\n",
    "        5. \"DO WE CARE ABOUT CONCUSSIONS OR NOT!\" [80]\n",
    "        6. \"Even if you disagree, why single out a single individual - you're being a bully by doing so.\" [257]\n",
    "        7. \"How to spot someone that works and pays taxes\" [278]\n",
    "        \n",
    "#### CoreNLP Parsing Performance:\n",
    "- CoreNLP has 41 sentences labeled as Questions.\n",
    "- TP = 40\n",
    "- FP = 1\n",
    "- FN = 41\n",
    "- TN = 615\n",
    "\n",
    "#### Regex Performance:\n",
    "- Regex has 74 sentences labeled as Questions.\n",
    "- TP = 74\n",
    "- FP = 0 (kinda impossible by definition)\n",
    "- FN = 7\n",
    "- TN = 616\n",
    "\n",
    "#### A Note about True Negatives:\n",
    "- Both approaches correctly label this as NotQuestion (cuz it's quoting):\n",
    "    - He said something like \"How is anyone supposed to learn anything when all the Muslims kids won't stop clapping?\" [297]\n",
    "    - ...\"We can't possibly stand toe-to-toe against them in a conventional, army to army fight, so how do we protect ourselves while still maintaining our rights as a sovereign nation to chart our own path?\" [226]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples where it fails:\n",
    "#### CoreNLP Parsing:\n",
    "- False positives (incorrectly classified as questions):\n",
    "    - \"Couldn't do it\" [5]\n",
    "\n",
    "- False negatives (questions that CoreNLP missed out on):\n",
    "    - \"So Canadians are rapists and drug dealers?\" [7]\n",
    "    - \"[Grapefruit?\" [15]\n",
    "    - \"holy shit don't you have anything better to do.\" [22]\n",
    "    - \"Jesus fucking Christ how is this not top of the sub.\" [35]\n",
    "    - \"wat\" [42]\n",
    "    - \"Unless I misunderstood you (which frankly could be possible) are you trying to say that she isn't a credible authority because she says organic farms are bad?\" [57]\n",
    "    - \"Was wondering why this was up voted\" [62]\n",
    "    - \"DO WE CARE ABOUT CONCUSSIONS OR NOT!\" [80]\n",
    "    - \"In the playoffs?\" [86]\n",
    "    - \"Was Stewart mocking white dances or is he just a nerd?\" [88]\n",
    "    - \"George Takei sitting in a throne doing an evil laugh?\" [103]\n",
    "    - \"I know it's been a while, but didn't the Panthers used to have a good defense?\" [105]\n",
    "    - \"Like, 2 weeks ago?\" [105]\n",
    "    - \"Blaming shitty defense on the tablets?\" [117]\n",
    "    - \"In this case, you would want the grower, right?\" [125]\n",
    "    - \"Sure, he's a bit older but who can they field at center better than him?\" [131]\n",
    "    - \"Why all the hate?\" [132]\n",
    "    - \"Mike Tolbert?\" [137]\n",
    "    - \"Bust?\" [142]\n",
    "    - \"Live up to crazy expectations?\" [142]\n",
    "    - \"Really?\" [153]\n",
    "    - \"You've never heard Romney come off as stiff or robotic?\" [153]\n",
    "    - \"And who are these people thinking Hillary should smile more?\" [153]\n",
    "    - \"You think that's why they don't like Cruz?\" [169]\n",
    "    - \"By your argument, no republican can win, so what does it matter who they support?\" [170]\n",
    "    - \"Jesus, are there really Gaddafi apologists?\" [178]\n",
    "    - \"Well, seeing how there is no evidence of Rice using RNC, coupled with lots of testimony now and during the time that she rarely used email and when she did she used the state department, why wouldn't you?\" [180]\n",
    "    - \"I thought it was in the 40s?\" [192]\n",
    "    - \"Problems with the concept now?\" [212]\n",
    "    - \"I didn't see the video, but he just had to be joking right?\" [214]\n",
    "    - \"What market force would cause minimum wage to increase?\" [217]\n",
    "    - \"How?\" [228]\n",
    "    - \"With force?\" [228]\n",
    "    - \"Forever?\" [228]\n",
    "    - \"We're going to spend billions, probably *trillions* in the long-run preventing other polities from discovering nuclear tech?\" [228]\n",
    "    - \"What the fuck is up with /r/sweden Like who are the people posting in there?\" [256]\n",
    "    - \"Even if you disagree, why single out a single individual - you're being a bully by doing so.\" [257]\n",
    "    - \"How to spot someone that works and pays taxes\" [278]\n",
    "    - \"So why bring some bullshit argument you *know* is going to fail?\" [285]\n",
    "    - \"I know the cuck in the middle, who are the other cucks?\" [294]\n",
    "    \n",
    "#### Basic Regex:\n",
    "- False negatives (questions that Regex missed out on): [questions within brackets; questions without a '?'] Note it also correctly labels a quoting question as NotQuestion.\n",
    "    - \"holy shit don't you have anything better to do.\" [22]\n",
    "    - \"Jesus fucking Christ how is this not top of the sub.\" [35]\n",
    "    - \"wat\" [42]\n",
    "    - \"Was wondering why this was up voted\" [62]\n",
    "    - \"DO WE CARE ABOUT CONCUSSIONS OR NOT!\" [80]\n",
    "    - \"Even if you disagree, why single out a single individual - you're being a bully by doing so.\" [257]\n",
    "    - \"How to spot someone that works and pays taxes\" [278]\n",
    "    \n",
    "- False positives (incorrectly classified as questions): None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse parse trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_tree(comment):\n",
    "    # CoreNLP server:\n",
    "    res = annotate_comment(comment)\n",
    "\n",
    "    # Question if contains SBARQ and SQ\n",
    "    for output in res['sentences']:\n",
    "        parse_tree = output['parse']\n",
    "        print \"\\n\", parse_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"So Canadians are rapists and drug dealers?\", \"holy shit don't you have anything better to do.\",]\n",
    "#         \"Jesus fucking Christ how is this not top of the sub.\", \"wat\", \"Couldn't do it\", \\\n",
    "#         \"Unless I misunderstood you (which frankly could be possible) are you trying to say that she isn't a credible \\\n",
    "#          authority because she says organic farms are bad?\", \"Was wondering why this was up voted\", \\\n",
    "#         \"DO WE CARE ABOUT CONCUSSIONS OR NOT!\", \"In the playoffs?\", \"Was Stewart mocking white dances or is he just a nerd?\", \\\n",
    "#         \"Sure, he's a bit older but who can they field at center better than him?\", \"Why all the hate?\", \"Mike Tolbert?\", \\\n",
    "#         \"Bust?\", \"Live up to crazy expectations?\"]\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "So Canadians are rapists and drug dealers?\n",
      "\n",
      "(ROOT\n",
      "  (S (RB So)\n",
      "    (NP (NNPS Canadians))\n",
      "    (VP (VBP are)\n",
      "      (NP\n",
      "        (NP (NNS rapists))\n",
      "        (CC and)\n",
      "        (NP (NN drug) (NNS dealers))))\n",
      "    (. ?)))\n",
      "\n",
      "holy shit don't you have anything better to do.\n",
      "\n",
      "(ROOT\n",
      "  (S\n",
      "    (NP (JJ holy) (NN shit))\n",
      "    (VP (VBP do) (RB n't)\n",
      "      (SBAR\n",
      "        (S\n",
      "          (NP (PRP you))\n",
      "          (VP (VBP have)\n",
      "            (S\n",
      "              (NP (NN anything))\n",
      "              (ADJP (JJR better))\n",
      "              (S\n",
      "                (VP (TO to)\n",
      "                  (VP (VB do)))))))))\n",
      "    (. .)))\n"
     ]
    }
   ],
   "source": [
    "for comment in test:\n",
    "    print \"\\n\", comment\n",
    "    explore_tree(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(ROOT\n",
      "  (SBARQ\n",
      "    (WHADVP (WRB Why))\n",
      "    (SQ (VBP do)\n",
      "      (NP (PRP you))\n",
      "      (VP (VB care)))\n",
      "    (. ?)))\n"
     ]
    }
   ],
   "source": [
    "explore_tree(\"Why do you care?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
