{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract comments from Reddit pickles to pubhlish to MTurk:\n",
    "\n",
    "- Saves it as a CSV in /crowdsourcing/data/csvs/\n",
    "- Adds the extracted reply_ids to /crowdsourcing/data/reply_ids_extracted.txt | Makes sure that there are no duplicate comments extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from question_extractor import clean_text, extract_questions_regex\n",
    "# pd.set_option('display.max_colwidth', -1)\n",
    "# pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Can change these for every run ####\n",
    "BATCH_NUMBER = 3 # Batch number for MTurk\n",
    "N_SAMPLES = 420 # Number of samples from EACH subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ndg/users/sbagga1/unpalatable-questions/crowdsourcing/data/csvs/batch_3_6300.csv will be created in this run.\n"
     ]
    }
   ],
   "source": [
    "# Comments longer than 400 characters or shorter than 10 characters would be skipped.\n",
    "MAX_CHAR_LIMIT = 400\n",
    "MIN_CHAR_LIMIT = 10\n",
    "\n",
    "# Questions shorter than 4 characters would be skipped (that's most likely to be an extraction error)\n",
    "MIN_QUES_LIMIT = 4\n",
    "\n",
    "# Inspired from Antag-Stats \n",
    "# & https://www.vice.com/en_ca/article/8xxymb/here-are-reddits-whiniest-most-low-key-toxic-subreddits\n",
    "SUBREDDITS = ['The_Donald', 'politics', 'PoliticalDiscussion', 'Conservative',\n",
    "              'cringepics', 'cringe', '4chan', 'CringeAnarchy', 'KotakuInAction',\n",
    "              'ImGoingToHellForThis', 'TumblrInAction',\n",
    "              'nfl', 'sports', 'nba', 'hockey']\n",
    "\n",
    "# Output path for the CSV:\n",
    "df_csv_output_fname = '/home/ndg/users/sbagga1/unpalatable-questions/crowdsourcing/data/csvs/batch_'+\\\n",
    "                        str(BATCH_NUMBER)+'_'+str(N_SAMPLES*len(SUBREDDITS))+'.csv'\n",
    "\n",
    "# Sanity check:\n",
    "if os.path.exists(df_csv_output_fname):\n",
    "    print \"ERROR: CSV already exists.\", df_csv_output_fname\n",
    "else:\n",
    "    print \"{} will be created in this run.\".format(df_csv_output_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't sample duplicate reply IDs and Test Questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100\n",
      "Number of Test Questions:  350\n",
      "# Unique comments already extracted from pickles: 5106\n"
     ]
    }
   ],
   "source": [
    "# Reply IDs already covered:\n",
    "with open('/home/ndg/users/sbagga1/unpalatable-questions/crowdsourcing/data/reply_ids_extracted.txt', 'r') as f:\n",
    "    a = f.read().splitlines()\n",
    "print len(a)\n",
    "    \n",
    "# Test Questions:\n",
    "b = pd.read_csv('/home/ndg/users/sbagga1/unpalatable-questions/crowdsourcing/data/TestQuestions.csv', \\\n",
    "                lineterminator='\\n')['reply_id'].tolist()\n",
    "\n",
    "print \"Number of Test Questions: \", len(b)\n",
    "IDs_COVERED = set(a+b)\n",
    "print \"# Unique comments already extracted from pickles:\", len(IDs_COVERED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_dict = {'question':[], 'comment_text':[], 'reply_text':[], 'comment_id':[], 'reply_id':[], 'subreddit':[]}\n",
    "\n",
    "for subred in SUBREDDITS:\n",
    "    counter = 0\n",
    "    print \"Working on {} with counter-value: {}\".format(subred, counter)\n",
    "    with open('/home/ndg/users/sbagga1/unpalatable-questions/pickles/subreddit_interactions_commentsOnly/'+subred+'-comment_replies.pickle', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        \n",
    "    for user_tup, conversation in data.items():\n",
    "        for interaction in conversation: # interaction is a (comment,reply) tuple so its length is always 2            \n",
    "            comment_id = interaction[0][0]; comment_text = interaction[0][1]\n",
    "            reply_id = interaction[1][0]; reply_text = interaction[1][1]\n",
    "            \n",
    "            if reply_id in IDs_COVERED: # skip if already covered in a previous batch\n",
    "                continue\n",
    "            \n",
    "            if len(reply_text) > MAX_CHAR_LIMIT or len(comment_text) > MAX_CHAR_LIMIT: # Skip if either the comment/reply is too long  \n",
    "                continue\n",
    "                \n",
    "            if len(reply_text) < MIN_CHAR_LIMIT or len(comment_text) < MIN_CHAR_LIMIT: # Skip if either the comment/reply is too short\n",
    "                continue\n",
    "\n",
    "            if '&gt;' in comment_text or '&gt;' in reply_text: # Skip if comments quote other comments in the thread (avoid confusion)\n",
    "                continue\n",
    "                \n",
    "            clean_reply_text = clean_text(reply_text) # removes non-ASCII characters and URLs \n",
    "            \n",
    "            if '?' not in clean_reply_text: # Skip if no question mark present\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                questions = extract_questions_regex(clean_reply_text)\n",
    "            except:\n",
    "                print \"This didn't work: \", reply_text\n",
    "                continue\n",
    "                \n",
    "            if len(questions) > 1: # Skip if multiple questions present\n",
    "                continue\n",
    "            \n",
    "            # The list can still be empty even though there was '?' because (1) quoting questions (2) questions in brackets\n",
    "            if len(questions) == 0:\n",
    "                continue\n",
    "\n",
    "            q = questions[0].strip()\n",
    "            if len(q) < MIN_QUES_LIMIT: # Skip if the question extracted is really short\n",
    "                print \"Likely an extraction error: \", q\n",
    "                continue\n",
    "            \n",
    "            # If any of the values are NaN, skip row:\n",
    "            if type(q) != str or type(comment_text) != str or type(reply_text) != str:\n",
    "                print \"Skipping this row because all elements are not string: \", reply_id, comment_text, reply_text, q\n",
    "                print type(comment_text), type(reply_text), type(q)            \n",
    "                continue\n",
    "            \n",
    "            # Populate dictionary:\n",
    "            inp_dict['question'].append(q)\n",
    "            inp_dict['comment_text'].append(comment_text)\n",
    "            inp_dict['reply_text'].append(reply_text)\n",
    "            inp_dict['comment_id'].append(comment_id)\n",
    "            inp_dict['reply_id'].append(reply_id)\n",
    "            inp_dict['subreddit'].append(subred)\n",
    "            \n",
    "            counter += 1 # only gets incremented if the code makes it this far :D\n",
    "            if counter == N_SAMPLES:\n",
    "                break\n",
    "        if counter == N_SAMPLES:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6300, 6)\n",
      "Any Null Values: False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reply_text</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>reply_id</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hillary is anti-gun?</td>\n",
       "      <td>Hillary is anti-gun?\\nhttps://medium.com/@Jean...</td>\n",
       "      <td>Guns will be an important issue in this electi...</td>\n",
       "      <td>d25fh6j</td>\n",
       "      <td>d25j18a</td>\n",
       "      <td>The_Donald</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So are you telling me that there are not extre...</td>\n",
       "      <td>So are you telling me that there are not extre...</td>\n",
       "      <td>The issue isn't \"Blacks\", that's the equivalen...</td>\n",
       "      <td>d25nfay</td>\n",
       "      <td>d25nl5t</td>\n",
       "      <td>The_Donald</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So about the size of Rubio?</td>\n",
       "      <td>So about the size of Rubio?</td>\n",
       "      <td>One quarter of a child voted for Lubio?</td>\n",
       "      <td>d10llre</td>\n",
       "      <td>d10lubn</td>\n",
       "      <td>The_Donald</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                               Hillary is anti-gun?   \n",
       "1  So are you telling me that there are not extre...   \n",
       "2                        So about the size of Rubio?   \n",
       "\n",
       "                                          reply_text  \\\n",
       "0  Hillary is anti-gun?\\nhttps://medium.com/@Jean...   \n",
       "1  So are you telling me that there are not extre...   \n",
       "2                        So about the size of Rubio?   \n",
       "\n",
       "                                        comment_text comment_id reply_id  \\\n",
       "0  Guns will be an important issue in this electi...    d25fh6j  d25j18a   \n",
       "1  The issue isn't \"Blacks\", that's the equivalen...    d25nfay  d25nl5t   \n",
       "2            One quarter of a child voted for Lubio?    d10llre  d10lubn   \n",
       "\n",
       "    subreddit  \n",
       "0  The_Donald  \n",
       "1  The_Donald  \n",
       "2  The_Donald  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn into a dataframe:\n",
    "df = pd.DataFrame.from_dict(inp_dict, orient='columns')\n",
    "\n",
    "# Preview dataframe:\n",
    "cols = [u'question', u'reply_text', u'comment_text', u'comment_id', u'reply_id', u'subreddit']\n",
    "df = df[cols]\n",
    "print df.shape\n",
    "print \"Any Null Values:\", df.isnull().values.any()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.isnull().values.any(): # Sanity check: no NaN values in DataFrame\n",
    "    # Append to reply IDs covered:\n",
    "    with open('/home/ndg/users/sbagga1/unpalatable-questions/crowdsourcing/data/reply_ids_extracted.txt', 'a') as f:\n",
    "        for ID in df['reply_id'].tolist():\n",
    "            f.write(\"%s\\n\" % ID)\n",
    "\n",
    "    # Save to csv for tracking batches:\n",
    "    df.to_csv(df_csv_output_fname, index=None)\n",
    "    \n",
    "else:\n",
    "    print(\"ERROR: Null values in DataFrame. CSV not created..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fin."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
